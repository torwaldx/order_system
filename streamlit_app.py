import streamlit as st
import json

import db
from llm_api import get_order_process_chain


st.title("üí¨ –ß–∞—Ç –±–æ—Ç –¥–ª—è —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –∑–∞–∫–∞–∑–æ–≤ –≤ –ø–∏—Ü—Ü–µ—Ä–∏–∏")


if "messages" not in st.session_state:
    st.session_state.messages = []


for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


if prompt := st.chat_input("–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–µ—á–∞—Ç–∞–π—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ"):

    # Store and display the current prompt.
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate a response using the OpenAI API.
    chain = get_order_process_chain()
    answer = chain.invoke({"user_request": prompt})

    order = db.get_products_with_prices(json.loads(answer.content))
    order_text = "–í–∞—à –∑–∞–∫–∞–∑:"
    sum = 0
    for item in order['items']:
        order_text += f"\n\n{item['name']} - {item['quantity']} x {item['price']}"
        sum += item['quantity']*item['price']
    order_text += f"\n\n–ò—Ç–æ–≥: {sum}"

    # Stream the response to the chat using `st.write_stream`, then store it in 
    # session state.
    with st.chat_message("assistant"):
        st.markdown(order_text)

    st.session_state.messages.append({"role": "assistant", "content": order_text})
