import streamlit as st
import json
import os

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate, FewShotPromptTemplate
from langchain.chains import LLMChain

from langchain.schema.runnable import RunnablePassthrough, RunnableLambda

import db
import few_shot

# Show title and description.
st.title("üí¨ –ß–∞—Ç –±–æ—Ç –¥–ª—è —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –∑–∞–∫–∞–∑–æ–≤ –≤ –ø–∏—Ü—Ü–µ—Ä–∏–∏")


# Ask user for their OpenAI API key via `st.text_input`.
# Alternatively, you can store the API key in `./.streamlit/secrets.toml` and access it
# via `st.secrets`, see https://docs.streamlit.io/develop/concepts/connections/secrets-management


os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
llm = ChatOpenAI(
    openai_api_base='https://api.proxyapi.ru/openai/v1',
    model_name="gpt-4o-mini",
    temperature=0.0,
)


def debug_prompt(inputs):
    print("=== –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç ===")
    print(inputs.text)
    print("=====================")
    return inputs  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∞–ª—å—à–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

def get_order_process_chain():
    # –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–¥—Å–∫–∞–∑–æ–∫
    example_prompt = PromptTemplate.from_template(
        "–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {Question}\n–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã: {Products_name}"
    )

    # –®–∞–±–ª–æ–Ω –¥–ª—è few-shot –ø–æ–¥—Å–∫–∞–∑–æ–∫
    few_shot_prompt_template = FewShotPromptTemplate(
        examples=[],
        example_prompt=example_prompt,
        prefix="–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:",
        suffix="",
        input_variables=["user_request"]
    )

    # –û—Å–Ω–æ–≤–Ω–æ–π —à–∞–±–ª–æ–Ω –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
    get_products_template = """–¢—ã - —É–º–Ω—ã–π –ò–ò –ø–æ–º–æ—â–Ω–∏–∫ - –ø–æ–º–æ–≥–∞–µ—à—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–∑–∏–Ω—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ.
    –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–æ–≤–∞—Ä—ã - –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Å–∫–∞–∑–∫–∏ –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–¥–Ω—É –º–∞–ª–µ–Ω—å–∫—É—é –ø–∏—Ü—Ü—É –∏ –Ω–∞–ø–∏—Ç–æ–∫.
    –ò—Å—Ö–æ–¥—è –∏–∑ –ø–µ—Ä–µ—á–Ω—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è , —Å—Ñ–æ—Ä–º–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞.
    –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ.
    –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ —è–≤–Ω–æ, –æ—Ü–µ–Ω–∏ –µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —É–∫–∞–∂–∏ "1" –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
    –¢—ã –º–æ–∂–µ—à—å –≤—ã–±–∏—Ä–∞—Ç—å —Ç–æ–≤–∞—Ä—ã —Ç–æ–ª—å–∫–æ –∏–∑ –ø–µ—Ä–µ—á–Ω—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ü–µ–Ω–∞–º–∏, –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤.

    –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: JSON-–æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º "items", —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏ "name" (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞) –∏ "quantity" (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ).
    –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ JSON-–æ–±—ä–µ–∫—Ç–æ–º –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    –ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:
    –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "–î–≤–µ –±–æ–ª—å—à–∏—Ö –ø–µ–ø–µ—Ä—Ä–æ–Ω–∏ –∏ 3 –Ω–∞–ø–∏—Ç–∫–∞"
    –û—Ç–≤–µ—Ç:
    {{
        "items": [
            {{"name": "–ü–µ–ø–ø–µ—Ä–æ–Ω–∏ Large", "quantity": 2}},
            {{"name": "–î–æ–±—Ä—ã–π –ö–æ–ª–∞ Small", "quantity": 3}}
        ]
    }}

    {few_shot}

    –í–æ—Ç –ø–µ—Ä–µ—á–µ–Ω—å –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (—Ç–æ–≤–∞—Ä | —Ç–∏–ø | —Ü–µ–Ω–∞):
    {products}

    –¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_request}
    """

    base_prompt = PromptTemplate.from_template(get_products_template)

    
    chain = (
        RunnablePassthrough.assign(
            products=lambda _: db.get_products_str(),
            few_shot=lambda inputs: few_shot_prompt_template.copy(
                update={"examples": few_shot.get_fewshot(inputs["user_request"])}
            ).format(user_request=inputs["user_request"])
        )
        | base_prompt
        # | RunnableLambda(debug_prompt)  # –í—ã–≤–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ LLM
        | llm
    )
    return chain



# Create a session state variable to store the chat messages. This ensures that the
# messages persist across reruns.
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display the existing chat messages via `st.chat_message`.
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Create a chat input field to allow the user to enter a message. This will display
# automatically at the bottom of the page.
if prompt := st.chat_input("–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–µ—á–∞—Ç–∞–π—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ"):

    # Store and display the current prompt.
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate a response using the OpenAI API.
    chain = get_order_process_chain()
    answer = chain.invoke({"user_request": prompt})

    order = db.get_products_with_prices(json.loads(answer.content))
    order_text = "\n\n".join([f"{item['name']} - {item['quantity']} x {item['price']}" for item in order['items']])


    # Stream the response to the chat using `st.write_stream`, then store it in 
    # session state.
    with st.chat_message("assistant"):
        st.markdown(order_text)

    st.session_state.messages.append({"role": "assistant", "content": order_text})
